{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "65469c53",
   "metadata": {},
   "source": [
    "# Credit Approval Modeling\n",
    "\n",
    "**Goal:** Binary classification.\n",
    "\n",
    "**You will learn to:**\n",
    "- Inspect and clean a dataset (missing values, types).\n",
    "- Build a preprocessing pipeline for numeric & categorical columns.\n",
    "- Train and compare three models: Logistic Regression (baseline), Random Forest, and Gradient Boosting.\n",
    "- Evaluate with Accuracy, Classification Report, ROC AUC, and ROC curves.\n",
    "- Peek into feature importance/coefficients.\n",
    "- Work on storytelling.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fcfc052b",
   "metadata": {},
   "source": [
    "## 1. Setup & Imports\n",
    "\n",
    "Read the data using Pandas `read_csv` function. It has 16 columns and no header row. The data was objetained from this [link](https://archive.ics.uci.edu/dataset/27/credit+approval).\n",
    "\n",
    "Description of data given in source website - \n",
    "\n",
    "> This file concerns credit card applications.  All attribute names and values have been changed to meaningless symbols to protect confidentiality of the data.\n",
    ">This dataset is interesting because there is a good mix of attributes -- continuous, nominal with small numbers of values, and nominal with larger numbers of values.  There are also a few missing values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fcfd3b5f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9b9cf0b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18d6628d",
   "metadata": {},
   "source": [
    "## 2. Load and Peek at the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "16573bf1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>A1</th>\n",
       "      <th>A2</th>\n",
       "      <th>A3</th>\n",
       "      <th>A4</th>\n",
       "      <th>A5</th>\n",
       "      <th>A6</th>\n",
       "      <th>A7</th>\n",
       "      <th>A8</th>\n",
       "      <th>A9</th>\n",
       "      <th>A10</th>\n",
       "      <th>A11</th>\n",
       "      <th>A12</th>\n",
       "      <th>A13</th>\n",
       "      <th>A14</th>\n",
       "      <th>A15</th>\n",
       "      <th>A16</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>b</td>\n",
       "      <td>30.83</td>\n",
       "      <td>0.000</td>\n",
       "      <td>u</td>\n",
       "      <td>g</td>\n",
       "      <td>w</td>\n",
       "      <td>v</td>\n",
       "      <td>1.25</td>\n",
       "      <td>t</td>\n",
       "      <td>t</td>\n",
       "      <td>1</td>\n",
       "      <td>f</td>\n",
       "      <td>g</td>\n",
       "      <td>202.0</td>\n",
       "      <td>0</td>\n",
       "      <td>+</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>a</td>\n",
       "      <td>58.67</td>\n",
       "      <td>4.460</td>\n",
       "      <td>u</td>\n",
       "      <td>g</td>\n",
       "      <td>q</td>\n",
       "      <td>h</td>\n",
       "      <td>3.04</td>\n",
       "      <td>t</td>\n",
       "      <td>t</td>\n",
       "      <td>6</td>\n",
       "      <td>f</td>\n",
       "      <td>g</td>\n",
       "      <td>43.0</td>\n",
       "      <td>560</td>\n",
       "      <td>+</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>a</td>\n",
       "      <td>24.50</td>\n",
       "      <td>0.500</td>\n",
       "      <td>u</td>\n",
       "      <td>g</td>\n",
       "      <td>q</td>\n",
       "      <td>h</td>\n",
       "      <td>1.50</td>\n",
       "      <td>t</td>\n",
       "      <td>f</td>\n",
       "      <td>0</td>\n",
       "      <td>f</td>\n",
       "      <td>g</td>\n",
       "      <td>280.0</td>\n",
       "      <td>824</td>\n",
       "      <td>+</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>b</td>\n",
       "      <td>27.83</td>\n",
       "      <td>1.540</td>\n",
       "      <td>u</td>\n",
       "      <td>g</td>\n",
       "      <td>w</td>\n",
       "      <td>v</td>\n",
       "      <td>3.75</td>\n",
       "      <td>t</td>\n",
       "      <td>t</td>\n",
       "      <td>5</td>\n",
       "      <td>t</td>\n",
       "      <td>g</td>\n",
       "      <td>100.0</td>\n",
       "      <td>3</td>\n",
       "      <td>+</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>b</td>\n",
       "      <td>20.17</td>\n",
       "      <td>5.625</td>\n",
       "      <td>u</td>\n",
       "      <td>g</td>\n",
       "      <td>w</td>\n",
       "      <td>v</td>\n",
       "      <td>1.71</td>\n",
       "      <td>t</td>\n",
       "      <td>f</td>\n",
       "      <td>0</td>\n",
       "      <td>f</td>\n",
       "      <td>s</td>\n",
       "      <td>120.0</td>\n",
       "      <td>0</td>\n",
       "      <td>+</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  A1     A2     A3 A4 A5 A6 A7    A8 A9 A10  A11 A12 A13    A14  A15 A16\n",
       "0  b  30.83  0.000  u  g  w  v  1.25  t   t    1   f   g  202.0    0   +\n",
       "1  a  58.67  4.460  u  g  q  h  3.04  t   t    6   f   g   43.0  560   +\n",
       "2  a  24.50  0.500  u  g  q  h  1.50  t   f    0   f   g  280.0  824   +\n",
       "3  b  27.83  1.540  u  g  w  v  3.75  t   t    5   t   g  100.0    3   +\n",
       "4  b  20.17  5.625  u  g  w  v  1.71  t   f    0   f   s  120.0    0   +"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\"cc_approvals.data\",header=None, na_values=[\"?\"])\n",
    "\n",
    "df.columns = [f\"A{i}\" for i in range(1,17)]\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8220c18a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "A3      0\n",
       "A8      0\n",
       "A9      0\n",
       "A10     0\n",
       "A11     0\n",
       "A12     0\n",
       "A13     0\n",
       "A15     0\n",
       "A16     0\n",
       "A4      6\n",
       "A5      6\n",
       "A6      9\n",
       "A7      9\n",
       "A1     12\n",
       "A2     12\n",
       "A14    13\n",
       "dtype: int64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isna().sum().sort_values(ascending=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da6b2519",
   "metadata": {},
   "source": [
    "## 3. Target Encoding & Column Types\n",
    "\n",
    "- Target (`A16`) values are `'+'` (approved) and `'-'` (denied).  \n",
    "- We map `'+' = 1` and `'-' = 0`.\n",
    "- Convert numeric-looking columns to numeric (coerce errors - NaN).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "568bb39f",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = df.drop(columns=[\"A16\"])\n",
    "y_raw = df[\"A16\"]\n",
    "\n",
    "y = y_raw.map({\"+\":1, \"-\":0})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "624c12b4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "A16\n",
       "0    383\n",
       "1    307\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "301a080d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 690 entries, 0 to 689\n",
      "Data columns (total 15 columns):\n",
      " #   Column  Non-Null Count  Dtype  \n",
      "---  ------  --------------  -----  \n",
      " 0   A1      678 non-null    object \n",
      " 1   A2      678 non-null    float64\n",
      " 2   A3      690 non-null    float64\n",
      " 3   A4      684 non-null    object \n",
      " 4   A5      684 non-null    object \n",
      " 5   A6      681 non-null    object \n",
      " 6   A7      681 non-null    object \n",
      " 7   A8      690 non-null    float64\n",
      " 8   A9      690 non-null    object \n",
      " 9   A10     690 non-null    object \n",
      " 10  A11     690 non-null    int64  \n",
      " 11  A12     690 non-null    object \n",
      " 12  A13     690 non-null    object \n",
      " 13  A14     677 non-null    float64\n",
      " 14  A15     690 non-null    int64  \n",
      "dtypes: float64(4), int64(2), object(9)\n",
      "memory usage: 81.0+ KB\n"
     ]
    }
   ],
   "source": [
    "x.info()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "cf49db98",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['A1', 'A4', 'A5', 'A6', 'A7', 'A9', 'A10', 'A12', 'A13']\n",
      "['A2', 'A3', 'A8', 'A11', 'A14', 'A15']\n"
     ]
    }
   ],
   "source": [
    "numeric_cols = [\"A2\", \"A3\", \"A8\", \"A11\", \"A14\", \"A15\"]\n",
    "\n",
    "for c in numeric_cols:\n",
    "    x[c] = pd.to_numeric(x[c], errors=\"coerce\")\n",
    "\n",
    "cat_cols = x.select_dtypes(include=[\"object\"]).columns.tolist()\n",
    "num_cols = [c for c in numeric_cols if c not in cat_cols]\n",
    "\n",
    "print(cat_cols)\n",
    "print(num_cols)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1de662d5",
   "metadata": {},
   "source": [
    "## 4. Train/Test Split\n",
    "\n",
    "We keep class proportions similar across train and test using `stratify=y`.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c84457e7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((552, 15), (138, 15), (552,), (138,))"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.2, random_state=42) # Random state is used to ensure reproducibility; \n",
    "# a seed value of 42 is used to ensure the same split every time the code is run.\n",
    "\n",
    "x_train.shape, x_test.shape, y_train.shape, y_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33474905",
   "metadata": {},
   "source": [
    "## 5. Preprocessing Pipelines\n",
    "\n",
    "- **Numeric:** median imputation + standardization  \n",
    "- **Categorical:** most-frequent imputation + one-hot encoding (ignore unknowns)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "a14a5074",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Data has numeric and categorical features.\n",
    "#Numeric features are scaled to have a mean of 0 and a standard deviation of 1.\n",
    "#Categorical features are one-hot encoded.\n",
    "#Unknown values are imputed with the most frequent value.\n",
    "\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "\n",
    "numeric_preprocessor = Pipeline(steps=[\n",
    "    (\"imputer\", SimpleImputer(strategy=\"median\")),\n",
    "    (\"scaler\", StandardScaler())\n",
    "])\n",
    "\n",
    "cat_preprocessor = Pipeline(steps=[\n",
    "    (\"imputer\", SimpleImputer(strategy=\"most_frequent\")),\n",
    "    (\"onehot\", OneHotEncoder(handle_unknown=\"ignore\", sparse_output=False))\n",
    "])\n",
    "\n",
    "preprocess = ColumnTransformer(transformers=[\n",
    "        (\"num\", numeric_preprocessor, num_cols),\n",
    "        (\"cat\", cat_preprocessor, cat_cols)\n",
    "    ]\n",
    ")\n",
    "\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05b82d2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "    \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "277b8af6",
   "metadata": {},
   "source": [
    "## 6. Train/Eval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "11961abf",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score, classification_report, roc_auc_score, roc_curve\n",
    "\n",
    "def fit_and_evaluate(model, x_train, y_train, x_test, y_test, name=\"(model)\"):\n",
    "    model.fit(x_train, y_train)\n",
    "    y_pred = model.predict(x_test)\n",
    "    y_pred_proba = model.predict_proba(x_test)[:, 1] if hasattr(model, \"predict_proba\") else None\n",
    "    acc = accuracy_score(y_test, y_pred)\n",
    "    report = classification_report(y_test, y_pred, digits=3)\n",
    "    auc = roc_auc_score(y_test, y_pred_proba) if y_pred_proba is not None else None\n",
    "    \n",
    "    print(f\"{name} - Accuracy: {acc:.4f}\")\n",
    "    print(f\"{name} - Classification Report:\")\n",
    "    print(report)\n",
    "    print(f\"{name} - ROC AUC: {auc:.4f}\")\n",
    "\n",
    "    return {\n",
    "        \"model\": model,\n",
    "        \"name\": name,\n",
    "        \"accuracy\": acc,\n",
    "        \"report\": report,\n",
    "        \"auc\": auc\n",
    "    }\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd772b24",
   "metadata": {},
   "source": [
    "## 7. Models\n",
    "\n",
    "We train three models with the same preprocessing:\n",
    "1. **Logistic Regression** – simple, strong baseline, interpretable coefficients  \n",
    "2. **Random Forest** – non-linear, handles interactions, has feature importances  \n",
    "3. **Gradient Boosting (sklearn)** – additive trees (note: this is **not** XGBoost; if you want XGBoost, install `xgboost` and swap the classifier)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "b1670d8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "\n",
    "models_lr = Pipeline(steps=[\n",
    "    (\"preprocess\", preprocess),\n",
    "    (\"model\", LogisticRegression(max_iter=200))\n",
    "])\n",
    "\n",
    "models_rfc = Pipeline(steps=[\n",
    "    (\"preprocess\", preprocess),\n",
    "    (\"model\", RandomForestClassifier(n_estimators=100, max_depth=None, min_samples_split=5, class_weight=\"balanced\", n_jobs=-1, random_state=42))\n",
    "])\n",
    "\n",
    "models_gbc = Pipeline(steps=[\n",
    "    (\"preprocess\", preprocess),\n",
    "    (\"model\", GradientBoostingClassifier(n_estimators=100, max_depth=3, learning_rate=0.05, random_state=42))\n",
    "])\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7891ee1",
   "metadata": {},
   "source": [
    "## 8. Training & Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "ecbec36e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression - Accuracy: 0.8261\n",
      "Logistic Regression - Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0      0.814     0.838     0.826        68\n",
      "           1      0.838     0.814     0.826        70\n",
      "\n",
      "    accuracy                          0.826       138\n",
      "   macro avg      0.826     0.826     0.826       138\n",
      "weighted avg      0.826     0.826     0.826       138\n",
      "\n",
      "Logistic Regression - ROC AUC: 0.8910\n",
      "Random Forest - Accuracy: 0.8406\n",
      "Random Forest - Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0      0.829     0.853     0.841        68\n",
      "           1      0.853     0.829     0.841        70\n",
      "\n",
      "    accuracy                          0.841       138\n",
      "   macro avg      0.841     0.841     0.841       138\n",
      "weighted avg      0.841     0.841     0.841       138\n",
      "\n",
      "Random Forest - ROC AUC: 0.9065\n",
      "Gradient Boosting - Accuracy: 0.8261\n",
      "Gradient Boosting - Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0      0.797     0.868     0.831        68\n",
      "           1      0.859     0.786     0.821        70\n",
      "\n",
      "    accuracy                          0.826       138\n",
      "   macro avg      0.828     0.827     0.826       138\n",
      "weighted avg      0.829     0.826     0.826       138\n",
      "\n",
      "Gradient Boosting - ROC AUC: 0.9059\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>name</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>report</th>\n",
       "      <th>auc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>(ColumnTransformer(transformers=[('num',\\n    ...</td>\n",
       "      <td>Random Forest</td>\n",
       "      <td>0.840580</td>\n",
       "      <td>precision    recall  f1-score   ...</td>\n",
       "      <td>0.906513</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>(ColumnTransformer(transformers=[('num',\\n    ...</td>\n",
       "      <td>Logistic Regression</td>\n",
       "      <td>0.826087</td>\n",
       "      <td>precision    recall  f1-score   ...</td>\n",
       "      <td>0.890966</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>(ColumnTransformer(transformers=[('num',\\n    ...</td>\n",
       "      <td>Gradient Boosting</td>\n",
       "      <td>0.826087</td>\n",
       "      <td>precision    recall  f1-score   ...</td>\n",
       "      <td>0.905882</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               model                 name  \\\n",
       "1  (ColumnTransformer(transformers=[('num',\\n    ...        Random Forest   \n",
       "0  (ColumnTransformer(transformers=[('num',\\n    ...  Logistic Regression   \n",
       "2  (ColumnTransformer(transformers=[('num',\\n    ...    Gradient Boosting   \n",
       "\n",
       "   accuracy                                             report       auc  \n",
       "1  0.840580                precision    recall  f1-score   ...  0.906513  \n",
       "0  0.826087                precision    recall  f1-score   ...  0.890966  \n",
       "2  0.826087                precision    recall  f1-score   ...  0.905882  "
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results = []\n",
    "\n",
    "results.append(fit_and_evaluate(models_lr, x_train, y_train, x_test, y_test, \"Logistic Regression\"))\n",
    "results.append(fit_and_evaluate(models_rfc, x_train, y_train, x_test, y_test, \"Random Forest\"))\n",
    "results.append(fit_and_evaluate(models_gbc, x_train, y_train, x_test, y_test, \"Gradient Boosting\"))\n",
    "\n",
    "summary = pd.DataFrame(results)\n",
    "summary.sort_values(by=\"accuracy\", ascending=False, inplace=True)\n",
    "summary \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3b9bda7",
   "metadata": {},
   "source": [
    "### 1. Accuracy\n",
    "\n",
    "**Definition:**  \n",
    "The fraction of correct predictions out of all predictions.\n",
    "\n",
    "**Significance:**  \n",
    "- Simple and intuitive measure of performance.  \n",
    "- Works well if classes are balanced.  \n",
    "- Can be misleading if data is imbalanced (e.g., 95% “negative” and 5% “positive”: a model that predicts everything as “negative” still gets 95% accuracy).  \n",
    "\n",
    "---\n",
    "\n",
    "### 2. Classification Report (Precision, Recall, F1-score)\n",
    "\n",
    "This expands accuracy into more detailed metrics for each class:\n",
    "\n",
    "#### Precision\n",
    "- **Definition:** Of all instances predicted positive, how many were actually positive?  \n",
    "- **Significance:**  \n",
    "  - High precision means fewer false alarms.  \n",
    "  - Useful in domains where false positives are costly (e.g., spam detection).  \n",
    "\n",
    "#### Recall (Sensitivity, True Positive Rate)\n",
    "- **Definition:** Of all actual positive instances, how many did we correctly identify?  \n",
    "- **Significance:**  \n",
    "  - High recall means fewer missed positives.  \n",
    "  - Important in healthcare, fraud detection, etc., where missing a positive case is critical.  \n",
    "\n",
    "#### F1-score\n",
    "- **Definition:** Harmonic mean of precision and recall.  \n",
    "- **Significance:**  \n",
    "  - Balances precision and recall.  \n",
    "  - Especially useful in imbalanced datasets where accuracy is misleading.  \n",
    "\n",
    "#### Support\n",
    "- **Definition:** Number of actual instances of each class.  \n",
    "- **Significance:** Helps contextualize precision/recall scores.  \n",
    "\n",
    "---\n",
    "\n",
    "### 3. ROC AUC (Area Under the ROC Curve)\n",
    "\n",
    "- **ROC Curve:** Plots True Positive Rate (Recall) vs. False Positive Rate at different probability thresholds.  \n",
    "- **AUC (Area Under Curve):** Single number summarizing the ROC curve.  \n",
    "  - Ranges from 0.5 (random guessing) to 1.0 (perfect model).  \n",
    "\n",
    "**Significance:**  \n",
    "- Threshold-independent: evaluates model’s ability to rank positives above negatives.  \n",
    "- Useful for comparing classifiers.  \n",
    "- Works well even with class imbalance.  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95d6d485",
   "metadata": {},
   "source": [
    "## 9. ROC Curves\n",
    "\n",
    "Single chart with the ROC curves from each model.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "0c0345b6",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'y_pred_proba'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyError\u001b[39m                                  Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[22]\u001b[39m\u001b[32m, line 6\u001b[39m\n\u001b[32m      3\u001b[39m plt.figure(figsize=(\u001b[32m10\u001b[39m, \u001b[32m6\u001b[39m))\n\u001b[32m      5\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m r \u001b[38;5;129;01min\u001b[39;00m results:\n\u001b[32m----> \u001b[39m\u001b[32m6\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m r[\u001b[33m\"\u001b[39m\u001b[33my_pred_proba\u001b[39m\u001b[33m\"\u001b[39m] \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m      7\u001b[39m         \u001b[38;5;28;01mcontinue\u001b[39;00m\n\u001b[32m      9\u001b[39m     fpr, tpr, thresholds = roc_curve(r[\u001b[33m\"\u001b[39m\u001b[33my_test\u001b[39m\u001b[33m\"\u001b[39m], r[\u001b[33m\"\u001b[39m\u001b[33my_pred_proba\u001b[39m\u001b[33m\"\u001b[39m])\n",
      "\u001b[31mKeyError\u001b[39m: 'y_pred_proba'"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1000x600 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "\n",
    "for r in results:\n",
    "    if r[\"y_pred_proba\"] is not None:\n",
    "        continue\n",
    "    \n",
    "    fpr, tpr, thresholds = roc_curve(r[\"y_test\"], r[\"y_pred_proba\"])\n",
    "    plt.plot(fpr, tpr, label=f\"{r['name']} (AUC = {r['auc']:.2f})\")\n",
    "\n",
    "plt.plot([0, 1], [0, 1], \"k--\", label=\"Random Guessing\")\n",
    "plt.xlabel(\"False Positive Rate\")\n",
    "plt.ylabel(\"True Positive Rate\")\n",
    "plt.title(\"ROC Curve\")\n",
    "plt.legend()\n",
    "plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "DataMining",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
