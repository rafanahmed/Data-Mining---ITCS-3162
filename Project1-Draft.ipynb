{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4260ce1f",
   "metadata": {},
   "source": [
    "# \"Digital Gold\": A Visual Analysis of Bitcoin as a Hedge Against Inflation and Market Volatility\n",
    "\n",
    "As inflation creates general unease within our economy, we're seeing a rise in investments into alternative commodities and assets that are said to \"hedge\"â€”an investment that's expected to hold or increase its value over time, even as the cost of everything else goes up. One of these assets is Bitcoin ($BTC), a cryptocurrency often dubbed \"Digital Gold\" based on popular sentiment. \n",
    "\n",
    "As governments printed significant amounts of money, especially in recent years, many investors have looked for assets that can protect their wealth from the resulting inflation. Proponents claim Bitcoin, with its fixed supply, is a perfect candidate. This project explores and investigates this popular claim, asking:\n",
    "\n",
    "- **Does Bitcoin's volatility change during periods of high vs. low inflation? A good hedge should ideally be stable, but what if Bitcoin becomes more chaotic and unpredictable precisely when you need it to be a safe haven?**\n",
    "- **During major stock market crashes, does Bitcoin act as a 'safe haven' by holding its value, or does it crash even harder?**\n",
    "- **Does the relationship between Bitcoin and inflation stay the same over time, or does it change depending on the market environment?**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df2d8550",
   "metadata": {},
   "source": [
    "## Mining Metrics: Sourcing Our Datasets\n",
    "Several key financial and economic datasets are needed to investigate the relationship between Bitcoin, inflation, and broader market behavior. The following data was sourced from Yahoo Finance (via the `yfinance` library) and the Federal Reserve Economic Data (FRED) database.\n",
    "\n",
    "**1. Bitcoin (BTC-USD)**\n",
    "> This dataset contains the daily price history of Bitcoin valued in U.S. Dollars, which is central to evaluating its performance as an asset.\n",
    "\n",
    "- **Source:** Yahoo Finance (`yfinance` Ticker: BTC-USD)\n",
    "- **Link:** https://finance.yahoo.com/quote/BTC-USD/\n",
    "- **Features**:\n",
    "    - **Date:** The trading day\n",
    "    - **Open/High/Low/Close:** The opening, highest, lowest, and closing prices for the day.\n",
    "    - **Volume:** The total number of Bitcoins traded.\n",
    "\n",
    "**2. S&P 500 Index (^GSPC)**\n",
    "> This data tracks the performance of 500 of the largest publicly-traded companies in the United States, offering a snapshot of the overall health of the U.S. stock market. This is essential for analyzing how Bitcoin behaves during broad market movements and crashes.\n",
    "\n",
    "- **Source:** Yahoo Finance (`yfinance` Ticker: ^GSPC)\n",
    "- **Link:** https://finance.yahoo.com/quote/GSPC/\n",
    "- **Features:** Includes the same trading day, OHLC (Open, High, Low, Close) and Volume data points as the Bitcoin dataset, but for the S&P 500 index.\n",
    "\n",
    "**3. CBOE Volatility Index (^VIX)**\n",
    "> Also known as a \"fear index,\" the VIX measures expected market volatility. It is crucial for understanding how Bitcoin's own volatility and price action correlate with periods of market fear and uncertainty.\n",
    "\n",
    " - **Source:** Yahoo Finance (`yfinance` Ticker: ^VIX)\n",
    " - **Link:** https://finance.yahoo.com/quote/^VIX/\n",
    " - **Features:** Contains OHLC data points representing the daily values of the index.\n",
    "\n",
    "**4. Gold Futures (GC=F)**\n",
    "> This dataset tracks the price of gold, the traditional safe-haven asset. It provides a direct benchmark to compare against Bitcoin's performance as an inflation hedge and store of value.\n",
    "\n",
    " - **Source:** Yahoo Finance (`yfinance` Ticker: GC=F)\n",
    " - **Link:** https://finance.yahoo.com/quote/GC=F/\n",
    " - **Features:** Contains OHLC and Volume data for gold futures contracts.\n",
    "\n",
    "**5. U.S Inflation (CPIAUCSL)**\n",
    "> This is the primary measure of inflation. The dataset tracks the average change in prices paid by urban consumers for a basket of goods and services.\n",
    "\n",
    " - **Source:** Federal Reserve Economic Data (FRED Ticker: CPIAUCSL)\n",
    " - **Link:** https://fred.stlouisfed.org/series/CPIAUCSL\n",
    " - **Features:**\n",
    "    - **Date:** The date of the observation\n",
    "    - **Value:** A seasonally adjusted index value (1982-1984 = 100) representing the relative cost of goods.\n",
    "\n",
    "**6. Effective Federal Funds Rate (DFF)**\n",
    "> This dataset tracks the interest rate at which commercial banks lend reserves to each other overnight. It reflects the U.S. monetary policy stance, providing essential context on the macroeconomic environment influencing asset prices.\n",
    "\n",
    " - **Source:** Federal Reserve Economic Data (FRED Ticker: DFF)\n",
    " - **Link:** https://fred.stlouisfed.org/series/DFF\n",
    " - **Features:**\n",
    "    - **Date:** The date of the observation\n",
    "    - **Value:** The effective federal funds rate, expressed as a percentage."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0748a3ac",
   "metadata": {},
   "source": [
    "## Panning for Gold: Preprocessing the Datasets\n",
    "\n",
    "The goal is to create a clean dataset in which all variables are aligned in time and transformed into metrics for analysis.\n",
    "\n",
    "This involves five main preprocessing steps:\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8bfcbcb4",
   "metadata": {},
   "source": [
    "**Step 1: Loading the Datasets**\n",
    "\n",
    "We need to load all six datasets into our Jupyter Notebook. We'll use a common date range to ensure we're looking at the same period for all assets.\n",
    "\n",
    "We'll import the necessary Python libraries (`pandas`, `yfinance`, `pandas_datareader`) and download the time series for each of the six datasets, storing them in pandas DataFrames.\n",
    "\n",
    "To ensure the analytical integrity of the time-series calculation, the raw CPI data is first resampled to a clean monthly frequency ('MS'). On this uniform monthly series, we first calculate the year-over-year (YoY) inflation rate on the monthly CPI data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d90e54d",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install pandas yfinance pandas_datareader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9116996",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Libraries to install:\n",
    "import pandas as pd\n",
    "import yfinance as yf\n",
    "import pandas_datareader as pdr\n",
    "import datetime\n",
    "\n",
    "# Define tickers and Date Range. The start and end dates are set to cover from a long period ago to the present day.\n",
    "start_date = datetime.datetime(2010, 1, 1)\n",
    "end_date = datetime.datetime.now()\n",
    "yf_tickers = ['BTC-USD', '^GSPC', '^VIX', 'GC=F']\n",
    "fred_tickers = ['CPIAUCSL', 'DFF']\n",
    "\n",
    "# Download the data from Yahoo Finance using yf.download()\n",
    "#\n",
    "# Args:\n",
    "#   yf_tickers (list[str]): List of tickers to download from Yahoo Finance\n",
    "#   start (str): Start date for the data\n",
    "#   end (str): End date for the data\n",
    "# Returns:\n",
    "#   yf_data (pd.DataFrame): DataFrame containing the downloaded data\n",
    "yf_data = yf.download(yf_tickers, start=start_date, end=end_date)\n",
    "\n",
    "# Download the data from FRED using pdr.DataReader()\n",
    "#\n",
    "# Args:\n",
    "#   fred_tickers (list[str]): List of tickers to download from FRED\n",
    "#   'fred' (str): The name of the data source to use.\n",
    "#   start (str): Start date for the data\n",
    "#   end (str): End date for the data\n",
    "# Returns:\n",
    "#   fred_data (pd.DataFrame): DataFrame containing the downloaded data\n",
    "fred_data = pdr.DataReader(fred_tickers, 'fred', start=start_date, end=end_date)\n",
    "\n",
    "# We force the CPI data to a clean, monthly series by taking the first value of each month.\n",
    "# This fixes the root cause of the incorrect inflation calculation.\n",
    "fred_monthly = fred_data.resample('MS').first()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1eb4fba",
   "metadata": {},
   "source": [
    "**Step 2: Resampling and Merging**\n",
    "\n",
    "The market data (BTC, S&P 500, VIX, Gold) and the policy-related rate (DFF) are daily, while the core inflation data (CPI) is monthly. We need to get everything onto a single daily timeline.\n",
    "\n",
    "We'll select a single, representative column from each of the daily market datasets (e.g., `Close`). Then, we'll merge the daily datasets into one primary DataFrame using the date as the common index.\n",
    "\n",
    " We merge this monthly rate into our daily DataFrame and use a method called forward-filling (`ffill`). This is the correct approach because the inflation rate for a given month is considered the prevailing rate for the entire month until the next value is announced. The `ffill` method achieves this by carrying the last valid observation forward to fill any subsequent gaps (e.g., a series like `[10, NaN, NaN, 15]` becomes `[10, 10, 10, 15]`)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5cedef74",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate Monthly Inflation Rate FIRST\n",
    "# 'CPIAUCSL' column is an index. To get the inflation rate,\n",
    "# we calculate the percentage change from 12 months prior.\n",
    "# We multiply by 100 to express it as a percentage.\n",
    "#\n",
    "# Args:\n",
    "#   periods (int): The number of periods to look back for the calculation (12 for YoY).\n",
    "#\n",
    "# Returns:\n",
    "#   (pd.Series): A new Series containing the percentage change values.\n",
    "fred_monthly['Inflation_Rate'] = fred_monthly['CPIAUCSL'].pct_change(periods=12) * 100\n",
    "\n",
    "# We are selecting the 'Close' price for each asset and renaming columns.\n",
    "prices = yf_data['Close'].copy()\n",
    "prices.rename(columns={'BTC-USD': 'Bitcoin', '^GSPC': 'SP500', '^VIX': 'VIX', 'GC=F': 'Gold'}, inplace=True)\n",
    "\n",
    "# Combine All Daily Datasets:\n",
    "# DFF data is already daily, so we can merge it directly with our daily prices.\n",
    "#\n",
    "# Args:\n",
    "#   prices (pd.DataFrame): The left DataFrame with daily stock prices.\n",
    "#   fred_data[['DFF', 'Inflation_Rate']] (pd.DataFrame): The right DataFrame with select FRED data.\n",
    "#   left_index (bool): Use the index from the `prices` DataFrame as the join key.\n",
    "#   right_index (bool): Use the index from the `fred_data['DFF']` Series as the join key.\n",
    "#   how (str): Type of merge. 'left' keeps all rows/indices from the left DataFrame.\n",
    "#\n",
    "# Returns:\n",
    "#   daily_data (pd.DataFrame): A new DataFrame containing the merged data.\n",
    "combined_df = pd.merge(prices, fred_data[['DFF']], left_index=True, right_index=True, how='left')\n",
    "combined_df = pd.merge(combined_df, fred_monthly['Inflation_Rate'], left_index=True, right_index=True, how='left')\n",
    "\n",
    "\n",
    "# Forward-fill the entire DataFrame to handle the monthly inflation rate and any missing\n",
    "# values from weekends and holidays for the other market assets.\n",
    "#\n",
    "# Args:\n",
    "#   method (str): The method used to fill missing values. 'ffill' stands for 'forward fill',\n",
    "#                 which propagates the last valid observation forward.\n",
    "#   inplace (bool): If True, the operation is performed directly on the object and modifies it.\n",
    "#\n",
    "# Returns:\n",
    "#   None: When inplace=True, the method modifies the DataFrame directly and returns None.\n",
    "combined_df.fillna(method='ffill', inplace=True)\n",
    "\n",
    "# Drop any remaining rows with NaN values. This removes the initial period\n",
    "# before Bitcoin's data was available, ensuring all series start on the same day.\n",
    "analysis_df = combined_df.dropna()\n",
    "\n",
    "\n",
    "print(\"--- Final Analysis-Ready DataFrame Head ---\")\n",
    "print(analysis_df.head())\n",
    "\n",
    "print(\"\\n--- Final Analysis-Ready DataFrame Tail ---\")\n",
    "print(analysis_df.tail())\n",
    "\n",
    "# The missing values count for all columns should now be 0.\n",
    "print(\"\\n--- Final Missing Values Check ---\")\n",
    "print(analysis_df.isnull().sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8ef37d4",
   "metadata": {},
   "source": [
    "**Step 3: Handling Missing Values (NaNs)**\n",
    "\n",
    "Financial datasets often have missing values, typically on weekends and holidays when markets are closed. Our merged dataset will have these gaps.\n",
    "\n",
    "We will again use the forward-fill (`ffill`) method on the entire dataset. This will propagate the last valid observation forward to fill any gaps.\n",
    "\n",
    "The value of an asset on a non-trading day (like a Saturday) is the same as its closing price on the last trading day (Friday). Forward-filling correctly handles these non-trading periods."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "208b3628",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The .fillna(method='ffill') command works on the entire DataFrame. This handles gaps from weekends and holidays.\n",
    "cleaned_df = combined_df.fillna(method='ffill')\n",
    "\n",
    "# After forward-filling, there might still be NaNs at the very start of the dataset\n",
    "# if one asset's history began later than others (like Bitcoin).\n",
    "# .dropna() will remove these initial rows where we have incomplete data.\n",
    "#\n",
    "# Args:\n",
    "#   (no arguments): Uses default settings to drop rows, which are the following:\n",
    "#   - axis=0: Drops rows containing missing values (default).\n",
    "#   - how='any': Drops a row if at least one NaN is present (default).\n",
    "#\n",
    "# Returns:\n",
    "#   analysis_df (pd.DataFrame): A new DataFrame with rows containing any NaN values removed.\n",
    "analysis_df = cleaned_df.dropna()\n",
    "\n",
    "\n",
    "print(\"--- Cleaned DataFrame Head ---\")\n",
    "print(analysis_df.head())\n",
    "\n",
    "print(\"\\n--- Cleaned DataFrame Tail ---\")\n",
    "print(analysis_df.tail())\n",
    "\n",
    "# The missing values count for all columns should now be 0.\n",
    "print(\"\\n--- Missing Values Check After Cleaning ---\")\n",
    "print(analysis_df.isnull().sum())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6ce8a78",
   "metadata": {},
   "source": [
    "**Step 4: Feature Engineering**\n",
    "\n",
    "Raw prices and index values aren't always the best for analysis. So we need to transform them into more insightful metrics that directly addresses the research questions. We engineer and create the following new feautures:\n",
    "- **Calculate Daily Returns**: For Bitcoin, the S&P 500, and Gold, calculate the daily percentage change. Daily returns normalize the data. A $100 price change means something very different for Bitcoin than it does for the S&P 500. Percentage returns allow us to compare their performance on an equal footing.\n",
    "- **Calculate Bitcoin Volatility**: Calculate a 30-day rolling standard deviation of Bitcoin's daily returns. A rolling volatility measure creates a new time series that explicitly quantifies how \"chaotic\" or \"stable\" Bitcoin's price has been over the preceding month."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6181e87e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate Daily Returns with pct_change()\n",
    "#\n",
    "# Args:\n",
    "#   (no arguments) OR periods (int): The number of periods to look back for the calculation.\n",
    "#                  e.g., 12 for a 12-month (Year-over-Year) change. No argument uses period=1.\n",
    "#\n",
    "# Returns:\n",
    "#   (pd.Series): A new Series containing the percentage change values.\n",
    "analysis_df['BTC_Return'] = analysis_df['Bitcoin'].pct_change()\n",
    "analysis_df['SP500_Return'] = analysis_df['SP500'].pct_change()\n",
    "analysis_df['Gold_Return'] = analysis_df['Gold'].pct_change()\n",
    "\n",
    "# Calculate Bitcoin Volatility using rolling() and std()\n",
    "# \n",
    "# .rolling() Args:\n",
    "#   window (int): The size of the moving window (e.g., 30 for a 30-day window).\n",
    "# .rolling() Returns:\n",
    "#   (Rolling object): An object that allows you to perform calculations over the window.\n",
    "#\n",
    "# .std() Args:\n",
    "#   (no arguments): Calculates the standard deviation of the values in the window.\n",
    "# .std() Returns:\n",
    "#   (pd.Series): A new Series containing the calculated rolling standard deviation.\n",
    "analysis_df['BTC_Volatility'] = analysis_df['BTC_Return'].rolling(window=30).std()\n",
    "\n",
    "# Finalize the Dataset\n",
    "# Calculations above create NaNs in the first few rows\n",
    "# (e.g., the first day has no \"return\", and the first 30 days have no \"volatility\").\n",
    "# We drop these rows to ensure our dataset is complete.\n",
    "analysis_df = analysis_df.dropna()\n",
    "\n",
    "\n",
    "print(\"--- Final DataFrame with Engineered Features ---\")\n",
    "print(analysis_df.head())\n",
    "\n",
    "print(\"\\n--- Final DataFrame Tail ---\")\n",
    "print(analysis_df.tail())\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f46ea32",
   "metadata": {},
   "source": [
    "**Step 5: Finalizing the Dataset**\n",
    "\n",
    "Finally, we'll clean up our DataFrame by selecting only the columns we need and dropping any initial rows that might have `NaN` values due to the rolling calculations.\n",
    "\n",
    "Our final DataFrame will contain:\n",
    "- Daily returns\n",
    "- VIX index\n",
    "- Inflation rate\n",
    "- Fed Funds Rate\n",
    "- Bitcoin's Rolling Volatility \n",
    "\n",
    "We'll then use `.dropna()` to remove any incomplete rows at the beginning.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b7a96e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a final DataFrame that contains only our engineered features and key indicators.\n",
    "# print(analysis_df.columns)\n",
    "final_df = analysis_df[[\n",
    "    'BTC_Return',\n",
    "    'SP500_Return',\n",
    "    'Gold_Return',\n",
    "    'VIX',              # Keeping the original VIX column\n",
    "    'Inflation_Rate',   # Keeping the original Inflation_Rate\n",
    "    'DFF',              # Keeping the original DFF column\n",
    "    'BTC_Volatility'\n",
    "]].copy()\n",
    "\n",
    "# Drop any rows with NaN values\n",
    "final_df = final_df.dropna()\n",
    "\n",
    "\n",
    "# FINAL DATASET\n",
    "print(\"--- COMPLETE DataFrame ---\")\n",
    "print(final_df.head())\n",
    "\n",
    "print(\"\\n--- Final NaN Check ---\")\n",
    "print(final_df.isnull().sum().sum()) # Should print 0"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dea3e56b",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "DataMining",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
